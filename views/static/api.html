<article class="markdown-body">
<h2><a id="user-content-main" class="anchor" href="#main" aria-hidden="true"><span class="octicon octicon-link"></span></a>API coming soon!</h2>

<p>In the mean time you can play around with our full source code. Pull requests for new features are appreciated!</p>

<h3><a id="user-content-haveerucrawler" class="anchor" href="#haveerucrawler" aria-hidden="true"><span class="octicon octicon-link"></span></a>Haveeru Crawler</h3>

<p>A crawler that fetches and indexes articles from Haveeru. Written for node js on top of redis, mongodb and elasticsearch</p>

<h3><a id="user-content-dependencies" class="anchor" href="#dependencies" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dependencies</h3>

<p>The following services are required to run the crawler</p>

<ul>
<li>mongodb</li>
<li>redis</li>
<li>elasticsearch</li>
</ul>

<h3><a id="user-content-installation-and-usage" class="anchor" href="#installation-and-usage" aria-hidden="true"><span class="octicon octicon-link"></span></a>Installation and Usage</h3>

<p>Do the following after cloning into or downloading haveerucrawler</p>

<h4><a id="user-content-install-package-dependencies" class="anchor" href="#install-package-dependencies" aria-hidden="true"><span class="octicon octicon-link"></span></a>Install Package Dependencies</h4>

<p>To install dependencies, cd into the application root directory</p>

<div class="highlight highlight-source-js"><pre>$ cd <span class="pl-k">/</span>path<span class="pl-k">/</span>to<span class="pl-k">/</span>haveeruexaminer</pre></div>

<p>then run npm install like so</p>

<div class="highlight highlight-source-js"><pre>$ npm install</pre></div>

<h4><a id="user-content-configure-the-crawler" class="anchor" href="#configure-the-crawler" aria-hidden="true"><span class="octicon octicon-link"></span></a>Configure the Crawler</h4>

<p>Configuration is pretty straightforward. It's just a matter of updating config.js with the relevant hostnames and port numbers for redis, mongodb and elasticsearch instances. Open config.js in any text editor</p>

<div class="highlight highlight-source-js"><pre>$ nano <span class="pl-smi">config</span>.<span class="pl-smi">js</span></pre></div>

<p>and change the following variables accordingly</p>

<div class="highlight highlight-source-js"><pre><span class="pl-c">// redis host -- this is a string</span>
<span class="pl-smi">config</span>.<span class="pl-smi">redis</span>.<span class="pl-c1">host</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">'</span>127.0.0.1<span class="pl-pds">'</span></span>;

<span class="pl-c">// redis port -- this is an integer</span>
<span class="pl-smi">config</span>.<span class="pl-smi">redis</span>.<span class="pl-c1">port</span> <span class="pl-k">=</span> <span class="pl-c1">6379</span>;

<span class="pl-c">// path to mongodb database -- this is a string</span>
<span class="pl-smi">config</span>.<span class="pl-smi">mongoServer</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">'</span>mongodb://localhost/database<span class="pl-pds">'</span></span>;

<span class="pl-c">// path to elasticsearch server(s) -- this is an array containing strings which must be comma-separated</span>
<span class="pl-smi">config</span>.<span class="pl-smi">elasticServer</span> <span class="pl-k">=</span> [<span class="pl-s"><span class="pl-pds">'</span>localhost:9200<span class="pl-pds">'</span></span>];</pre></div>

<h4><a id="user-content-set-up-the-index-and-run-application" class="anchor" href="#set-up-the-index-and-run-application" aria-hidden="true"><span class="octicon octicon-link"></span></a>Set up the Index and Run Application</h4>

<p>This is a crucial step as it creates the necessary index in elasticsearch. Make sure to do this before running the crawler. 
Run setup.js like so</p>

<div class="highlight highlight-source-js"><pre>$ node setup</pre></div>

<p>Finally, to start the crawler simply do</p>

<div class="highlight highlight-source-js"><pre>$ node index</pre></div>
</article>